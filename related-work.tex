\section{Related Work}
\label{sec:related}

The approaches to recover the FQNs for the API elements in incomplete
code snippets can be broadly classified into the following categories.
The first category is {\bf program analysis}. Partial Program Analysis
(PPA)~\cite{dagenais-oopsla08} resolves the types by applying a set of
heuristics on the syntactic constructs to infer the declared
types. RecoDoc~\cite{dagenais-icse12} uses PPA to infer links between
APIs and documentation. It requires all the target libraries to be
known. The second category of approaches leverages {\bf
  information retrieval}. Baker~\cite{liveapi14} tracks the scopes of
the names and the candidate lists are combined according to the
scoping rules and get smaller. COSTER~\cite{coster-ase19} formulates
the FQN problem as searching. It aims to match the context of the
query API element with the FQNs in the database regarding three
criteria on likelihood, context similarity, and name similarity.  The
third category is {\bf constraint-based}. Differing from COSTER,
SnR~\cite{snr-icse22} builds the knowledge of the constraints on API
elements and extracts such constraints in the code snippet to match
them against the knowledge base, and then solve them to derive the
FQNs.

Advances in machine learning (ML) enables the approaches to learn to
derive FQNs. StatType~\cite{icse18} learns to translate the code
without FQNs into the one having them. It treats source code as texts
and uses phrase-based statistical machine translation. Thus, it does
not consider program dependencies in deciding FQNs.

The closely related work to {\tool} is from Huang {\em et
  al.}~\cite{prompt-ase22}, which fine-tunes a masked language model
(MLM) as a neural knowledge base of program elements with a
``pre-train, prompt and predict'' paradigm from source code. In
comparison, there are key advances from {\tool}. First, Huang {\em et
  al.}~\cite{prompt-ase22} leverages the code before and after the
prediction point in the prompt-based paradigm to identify the API
element and decide the FQN. In contrast, we rely on the program
dependencies and relations among the API elements to derive their
FQNs. Second, while {\tool} uses the MLM to derive the FQNs for all
the API elements all at once, their approach works at each API element
one at a time, thus, do not leverage the constraints/relations among
them. Finally, their approach performs a prediction by attempting the
FQN with different lengths from the smallest to the largest in the
corpus. In practice, those values are not available. {\tool}
addresses that by an advanced technique.


Several approaches including Information retrieval (IR) are
used in linking texts in documentation to code, e.g., text
matching~\cite{bacchelli-icse10}, Latent Semantic
Indexing~\cite{marcus-icse03,delucia-ase08}, revised Vector Space
Model~\cite{buglocator-icse12,wang-icsm14}, Latent Dirichlet
Allocation~\cite{ase11,trase10}, Structure-oriented
Information Retrieval~\cite{saha-ase13,mcmillan11}, 
%probabilistic ranking~\cite{poshyvanyk07}, 
feature location~\cite{liu-ase07}.  Others use
%machine learning techniques including
learn-to-rank~\cite{ye-fse14}, deep learning~\cite{ase15-nier},
classifiers~\cite{kim-tse13}, etc. 
